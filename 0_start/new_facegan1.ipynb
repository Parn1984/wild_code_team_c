{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model functions from keras\n",
    "from keras.layers import Input\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# numpy for some mathematical operations\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Custom functions\n",
    "from utils.gan_func import build_discriminator\n",
    "from utils.gan_func import build_generator\n",
    "from utils.gan_func import get_random_noise\n",
    "from utils.gan_func import get_training_data\n",
    "from utils.gan_func import save_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# To avoid GPU memory issues\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.test.gpu_device_name())\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Parameters\n",
    "imgs_dir = 'data'\n",
    "\n",
    "image_height, image_width, channels = 64, 64, 3\n",
    "image_shape = (image_width, image_height, channels)\n",
    "\n",
    "random_noise_dimension = 100\n",
    "rows, columns = 4, 8\n",
    "\n",
    "save_images_interval = 100\n",
    "\n",
    "target_dir = 'generated_faces'\n",
    "\n",
    "target_fn = \"/generated\"\n",
    "\n",
    "# Model parameters\n",
    "\n",
    "use_pretrained_model = False\n",
    "\n",
    "pretrained_model_path_generator = \"saved_models/face_generator.h5\"\n",
    "pretrained_model_path_discriminator = \"saved_models/face_discriminator.h5\"\n",
    "\n",
    "epochs = 5000\n",
    "batch_size = 32\n",
    "\n",
    "start_epoch = 0\n",
    "if use_pretrained_model:\n",
    "    assert (start_epoch == 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_losses=[]\n",
    "d_acc=[]\n",
    "g_losses=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 99/7864 [00:00<00:07, 988.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7864/7864 [00:07<00:00, 1101.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get the real images\n",
    "training_data = get_training_data.get_training_data(imgs_dir, image_width, image_height, channels)\n",
    "\n",
    "# Map all values to a range between -1 and 1.\n",
    "training_data = training_data / 127.5 - 1.\n",
    "\n",
    "# =============================================================================\n",
    "# Set up the labels for generated and real images\n",
    "# =============================================================================\n",
    "\n",
    "# Two arrays of labels. Labels for real images: [1,1,1 ... 1,1,1], \n",
    "# labels for generated images: [0,0,0 ... 0,0,0]\n",
    "labels_for_real_images = np.ones((batch_size, 1)) - 0.15\n",
    "labels_for_generated_images = np.zeros((batch_size, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, dropout, momentum = 0.20, 0.0, 0.99\n",
    "optimizer = Adam(0.0002, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_pretrained_model:\n",
    "    generator     = load_model(pretrained_model_path_generator)\n",
    "    discriminator = load_model(pretrained_model_path_discriminator)\n",
    "else:\n",
    "    generator = build_generator.build_generator(random_noise_dimension, channels, alpha=alpha, momentum=momentum)\n",
    "    discriminator = build_discriminator.build_discriminator(image_shape, alpha=alpha, dropout=dropout, momentum=momentum)\n",
    "\n",
    "discriminator.compile(loss=\"binary_crossentropy\",\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=[\"accuracy\"])\n",
    "\n",
    "# Set up the actual GAN (= combined_model)\n",
    "random_input = Input(shape=(random_noise_dimension,))\n",
    "generated_image = generator(random_input)\n",
    "discriminator.trainable = False\n",
    "validity = discriminator(generated_image)\n",
    "combined_model = Model(random_input, validity)  # This is the actual GAN\n",
    "\n",
    "combined_model.compile(loss=\"binary_crossentropy\",\n",
    "                       optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0 [Discriminator loss: 2.040431, acc.: 0.00%] [Generator loss: 0.672704]\n",
      " 100 [Discriminator loss: 1.075348, acc.: 50.00%] [Generator loss: 4.271661]\n",
      " 200 [Discriminator loss: 0.253211, acc.: 50.00%] [Generator loss: 0.009905]\n",
      " 300 [Discriminator loss: 0.219132, acc.: 50.00%] [Generator loss: 0.009489]\n",
      " 400 [Discriminator loss: 0.229634, acc.: 50.00%] [Generator loss: 0.000495]\n",
      " 500 [Discriminator loss: 0.227082, acc.: 50.00%] [Generator loss: 0.001725]\n",
      " 600 [Discriminator loss: 0.237029, acc.: 50.00%] [Generator loss: 0.011363]\n",
      " 700 [Discriminator loss: 0.243629, acc.: 50.00%] [Generator loss: 0.005278]\n",
      " 800 [Discriminator loss: 0.214631, acc.: 50.00%] [Generator loss: 0.002619]\n",
      " 900 [Discriminator loss: 0.222094, acc.: 50.00%] [Generator loss: 0.005276]\n",
      "1000 [Discriminator loss: 0.236626, acc.: 50.00%] [Generator loss: 0.000932]\n",
      "1100 [Discriminator loss: 0.217680, acc.: 50.00%] [Generator loss: 0.003143]\n",
      "1200 [Discriminator loss: 0.212393, acc.: 50.00%] [Generator loss: 0.034570]\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Train GAN\n",
    "# =============================================================================\n",
    "\n",
    "for epoch in range(epochs):\n",
    "        # Select a random batch of real images\n",
    "    indices = np.random.randint(0, training_data.shape[0], batch_size)\n",
    "    real_images = training_data[indices]\n",
    "\n",
    "        # Generate random noise for a whole batch.\n",
    "    random_noise = get_random_noise.get_random_noise(rows, columns, random_noise_dimension)\n",
    "\n",
    "    discriminator.trainable = True \n",
    "\n",
    "        # Generate a batch of new images.\n",
    "    generated_images = generator.predict(random_noise)\n",
    "\n",
    "        # Train the discriminator on real images.\n",
    "    discriminator_loss_real = discriminator.train_on_batch(real_images, labels_for_real_images)\n",
    "        # Train the discriminator on generated images.\n",
    "    discriminator_loss_generated = discriminator.train_on_batch(generated_images, labels_for_generated_images)\n",
    "        # Calculate the average discriminator loss.\n",
    "    discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_generated)\n",
    "\n",
    "        # Train the generator using the combined model. Generator tries to trick \n",
    "        # discriminator into mistaking generated images as real.\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    labels_for_tricking_discriminator = np.ones((batch_size, 1))\n",
    "    generator_loss = combined_model.train_on_batch(random_noise, labels_for_tricking_discriminator)\n",
    "\n",
    "        # Training ends above (one iteration) \n",
    "        # This is only for display and saving models\n",
    "    if epoch % save_images_interval == 0:\n",
    "        save_images.save_images(epoch, random_noise_dimension, generator, target_dir, target_fn, start_epoch)\n",
    "        print(\"%4d [Discriminator loss: %f, acc.: %2.2f%%] [Generator loss: %f]\" %\n",
    "              (epoch, discriminator_loss[0], 100 * discriminator_loss[1], generator_loss))\n",
    "    d_losses.append(discriminator_loss[0])\n",
    "    d_acc.append(discriminator_loss[1])\n",
    "    g_losses.append(generator_loss)\n",
    "\n",
    "    \n",
    "        # Save the model for a later use\n",
    "    generator.save(pretrained_model_path_generator)\n",
    "    discriminator.save(pretrained_model_path_discriminator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(d_losses)\n",
    "# plt.plot(d_acc)\n",
    "plt.plot(g_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(d_losses, g_losses);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(d_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
